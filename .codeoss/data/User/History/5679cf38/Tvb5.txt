import os
import os
from google.cloud import bigquery

def export_bq_to_gcs(event, context):
    client = bigquery.Client()
    project_id = os.environ['banded-edge-437103-i9']
    dataset_id = os.environ['gcp_dataeng_demos']
    table_id = os.environ['demo_cf']
    bucket_name = os.environ['banded-edge-437103-i9']

    # Define destination file in GCS
    destination_uri = f"gs://{bucket_name}/updated_data_{context.timestamp}.csv"

    # Query to fetch updated rows (from last 1 minute)
    query = f"""
    SELECT * FROM `{project_id}.{dataset_id}.{table_id}`
    WHERE last_updated > TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 1 MINUTE)
    """

    # Configure extract job
    extract_job = client.query(query)

    # Execute the query and export to GCS
    extract_job.result()  # Wait for the job to finish
    print(f"Exported updated data to {destination_uri}")

